# Subprojeto: Debate Multimodelo com Mistral 7B via Ollama

## Objetivo

Permitir a participação automatizada do modelo Mistral 7B (via Ollama) em rodadas de debate de IA, integrando respostas do modelo a arquivos Markdown conforme o padrão de debates definido nas diretrizes.

## Estrutura Inicial

- Instalação e configuração do Ollama no Windows com suporte a CUDA
- Execução do modelo Mistral 7B (instruído)
- Script Python para enviar prompts e registrar respostas em arquivos de debate
- Integração com o fluxo de debates (pasta debates/ em projetos de ideias)

## Próximos Passos

1. Validar instalação do Ollama e do modelo Mistral 7B
2. Criar script Python para interação via linha de comando
3. Testar integração com arquivos de debate Markdown
4. Documentar fluxo de uso e automação

---

> Este subprojeto é independente e pode ser expandido para integrar outros modelos no futuro.
